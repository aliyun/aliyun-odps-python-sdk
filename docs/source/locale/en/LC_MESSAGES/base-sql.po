# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-2018, The Alibaba Group Holding Ltd.
# This file is distributed under the same license as the PyODPS package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PyODPS 0.7.16\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-06-29 16:26+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/base-sql.rst:4
msgid "SQL"
msgstr "SQL"

#: ../../source/base-sql.rst:6
msgid ""
"PyODPS支持ODPS SQL的查询，并可以读取执行的结果。 ``execute_sql`` 或者 ``run_sql`` 方法的返回值是 "
":ref:`运行实例 <instances>` 。"
msgstr ""
"PyODPS supports MaxCompute SQL queries and provides methods to read SQL "
"results. The ``execute_sql`` and ``run_sql`` methods return "
":ref:`instances <instances>` ."

#: ../../source/base-sql.rst:11
msgid ""
"并非所有在 ODPS Console 中可以执行的命令都是 ODPS 可以接受的 SQL 语句。 在调用非 DDL / DML "
"语句时，请使用其他方法，例如 GRANT / REVOKE 等语句请使用 ``run_security_query`` 方法，PAI 命令请使用 "
"``run_xflow`` 或 ``execute_xflow`` 方法。"
msgstr ""
"The commands that are executable in the MaxCompute Console may not be "
"executed as SQL statements in MaxCompute. Use other methods to execute "
"non-DDL/DML statements. For example, use ``run_security_query`` method to"
" execute GRANT/REVOKE statements. Use ``run_xflow`` or ``execute_xflow`` "
"method to execute PAI commands."

#: ../../source/base-sql.rst:18
msgid "执行SQL"
msgstr "Execute SQL statements"

#: ../../source/base-sql.rst:20
msgid ""
">>> o.execute_sql('select * from dual')  #  同步的方式执行，会阻塞直到SQL执行完成\n"
">>>\n"
">>> instance = o.run_sql('select * from dual')  # 异步的方式执行\n"
">>> print(instance.get_logview_address())  # 获取logview地址\n"
">>> instance.wait_for_success()  # 阻塞直到完成"
msgstr ""
">>> o.execute_sql('select * from dual')  #  synchronous way, will block "
"till SQL statement finishes execution\n"
">>>\n"
">>> instance = o.run_sql('select * from dual')  # asynchronous way\n"
">>> print(instance.get_logview_address())  # obtain LogView address\n"
">>> instance.wait_for_success()  # block till the statement finishes"

#: ../../source/base-sql.rst:31
msgid "设置运行参数"
msgstr "Set runtime parameters"

#: ../../source/base-sql.rst:33
msgid "有时，我们在运行时，需要设置运行时参数，我们可以通过设置 ``hints`` 参数，参数类型是dict。"
msgstr ""
"You can use the ``hints`` parameter to set runtime parameters. This "
"parameter is a dict type."

#: ../../source/base-sql.rst:35
msgid ""
">>> o.execute_sql('select * from pyodps_iris', "
"hints={'odps.sql.mapper.split.size': 16})"
msgstr ""

#: ../../source/base-sql.rst:39
msgid "我们可以对于全局配置设置sql.settings后，每次运行时则都会添加相关的运行时参数。"
msgstr ""
"You can set sql.settings globally. The relevant runtime parameters are "
"automatically added during each execution."

#: ../../source/base-sql.rst:41
msgid ""
">>> from odps import options\n"
">>> options.sql.settings = {'odps.sql.mapper.split.size': 16}\n"
">>> o.execute_sql('select * from pyodps_iris')  # 会根据全局配置添加hints"
msgstr ""
">>> from odps import options\n"
">>> options.sql.settings = {'odps.sql.mapper.split.size': 16}\n"
">>> o.execute_sql('select * from pyodps_iris')  # global hints configured"
" in options.sql.settings will be added"

#: ../../source/base-sql.rst:49
msgid "读取SQL执行结果"
msgstr "View SQL results"

#: ../../source/base-sql.rst:51
msgid "运行 SQL 的 instance 能够直接执行 ``open_reader`` 的操作，一种情况是SQL返回了结构化的数据。"
msgstr ""
"You can execute the ``open_reader`` method to retrieve SQL execution "
"results. In the following example, structured data is returned. "

#: ../../source/base-sql.rst:53
msgid ""
">>> with o.execute_sql('select * from dual').open_reader() as reader:\n"
">>>     for record in reader:\n"
">>>         # 处理每一个record"
msgstr ""
">>> with o.execute_sql('select * from dual').open_reader() as reader:\n"
">>>     for record in reader:\n"
">>>         # process every record"

#: ../../source/base-sql.rst:59
msgid "另一种情况是 SQL 可能执行的比如 ``desc``，这时通过 ``reader.raw`` 属性取到原始的SQL执行结果。"
msgstr ""
"When commands such as ``desc`` are executed, you can use the "
"``reader.raw`` attribute to get the original execution results. "

#: ../../source/base-sql.rst:61
msgid ""
">>> with o.execute_sql('desc dual').open_reader() as reader:\n"
">>>     print(reader.raw)"
msgstr ""

#: ../../source/base-sql.rst:66
msgid ""
"如果 `options.tunnel.use_instance_tunnel == True`，在调用 open_reader 时，PyODPS "
"会默认调用 Instance Tunnel， 否则会调用旧的 Result 接口。如果你使用了版本较低的 MaxCompute 服务，或者调用 "
"Instance Tunnel 出现了问题，PyODPS 会给出警告并自动降级到旧的 Result 接口，可根据警告信息判断导致降级的原因。如果 "
"Instance Tunnel 的结果不合预期， 请将该选项设为 `False`。在调用 open_reader 时，也可以使用 "
"``tunnel`` 参数来指定使用何种结果接口，例如"
msgstr ""
"If `options.tunnel.use_instance_tunnel` is set to `True` when open_reader"
" has been executed, PyODPS calls Instance Tunnel by default. If "
"`options.tunnel.use_instance_tunnel` is not set to `True` when "
"open_reader has been executed, PyODPS calls the old Result interface. If "
"you are using an old version of MaxCompute, or an error occurred when "
"calling Instance Tunnel, PyODPS reports a warning and automatically calls"
" the old Result interface instead. If the result of Instance Tunnel does "
"not meet your expectation, set this option to `False`. When calling "
"open_reader, you can also use the ``tunnel`` parameter to specify which "
"result interface to use. For example:"

#: ../../source/base-sql.rst:71
msgid ""
">>> # 使用 Instance Tunnel\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=True) as "
"reader:\n"
">>>     for record in reader:\n"
">>>         # 处理每一个record\n"
">>> # 使用 Results 接口\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=False) as"
" reader:\n"
">>>     for record in reader:\n"
">>>         # 处理每一个record"
msgstr ""
">>> # Use Instance Tunnel\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=True) as "
"reader:\n"
">>>     for record in reader:\n"
">>>         # process every record\n"
">>> # Use Results interface\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=False) as"
" reader:\n"
">>>     for record in reader:\n"
">>>         # process every record"

#: ../../source/base-sql.rst:82
msgid ""
"PyODPS 默认不限制能够从 Instance 读取的数据规模。对于受保护的 Project，通过 Tunnel 下载数据受限。此时， 如果 "
"`options.tunnel.limit_instance_tunnel` 未设置，会自动打开数据量限制。此时，可下载的数据条数受到 "
"Project 配置限制， 通常该限制为 10000 条。如果你想要手动限制下载数据的规模，可以为 open_reader 方法增加 "
"`limit` 选项， 或者设置 `options.tunnel.limit_instance_tunnel = True` 。"
msgstr ""
"By default, PyODPS does not limit the size of data that can be read from "
"an Instance. For protected projects, downloading data through the Tunnel "
"is limited. If `options.tunnel.limit_instance_tunnel` is not set, a data "
"cap is automatically enabled. The number of downloadable data records is "
"set in your project configuration. This is usually set to 10,000. If you "
"want to change the amount of downloadable data, you can add the `limit` "
"option in open_reader, or set `options.tunnel.limit_instance_tunnel` to "
"`True`."

#: ../../source/base-sql.rst:87
msgid ""
"如果你所使用的 MaxCompute 只能支持旧 Result 接口，同时你需要读取所有数据，可将 SQL 结果写入另一张表后用读表接口读取 "
"（可能受到 Project 安全设置的限制）。"
msgstr ""
"If the MaxCompute version you are using only supports the old Result "
"interface, and you need to read all data, you can export the SQL results "
"to another table and use these methods to read data. This may be limited "
"by project security settings."

#: ../../source/base-sql.rst:90
msgid "同时，PyODPS 支持直接将运行结果数据读成 pandas DataFrame。"
msgstr "PyODPS also supports reading data as pandas DataFrames."

#: ../../source/base-sql.rst:92
msgid ""
">>> # 直接使用 reader 的 to_pandas 方法\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=True) as "
"reader:\n"
">>>     # pd_df 类型为 pandas DataFrame\n"
">>>     pd_df = reader.to_pandas()"
msgstr ""
">>> # use to_pandas() method of the reader directly\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=True) as reader:\n"
">>>     # type of pd_df is pandas DataFrame\n"
">>>     pd_df = reader.to_pandas()"

#: ../../source/base-sql.rst:101
msgid "如果需要使用多核加速读取速度，可以通过 `n_process` 指定使用进程数:"
msgstr "If you want to accelerate data reading with multiple cores, you can specify `n_process` with number of cores you want to use:"

#: ../../source/base-sql.rst:105
msgid "目前多进程加速在 Windows 下无法使用。"
msgstr "Currently multiple process acceleration is not available under Windows."

#: ../../source/base-sql.rst:108
msgid ""
">>> import multiprocessing\n"
">>> n_process = multiprocessing.cpu_count()\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=True) as "
"reader:\n"
">>>     # n_process 指定成机器核数\n"
">>>     pd_df = reader.to_pandas(n_process=n_process)"
msgstr ""
">>> import multiprocessing\n"
">>> n_process = multiprocessing.cpu_count()\n"
">>> with o.execute_sql('select * from dual').open_reader(tunnel=True) as "
"reader:\n"
">>>     # n_process should be number of processes to use\n"
">>>     pd_df = reader.to_pandas(n_process=n_process)"

#: ../../source/base-sql.rst:118
msgid "设置alias"
msgstr "Set alias"

#: ../../source/base-sql.rst:120
msgid "有时在运行时，比如某个UDF引用的资源是动态变化的，我们可以alias旧的资源名到新的资源，这样免去了重新删除并重新创建UDF的麻烦。"
msgstr ""
"Some resources referenced by a UDF are dynamically changing at runtime. "
"You can create an alias for the old resource and use it as a new "
"resource."

#: ../../source/base-sql.rst:122
msgid ""
"from odps.models import Schema\n"
"\n"
"myfunc = '''\\\n"
"from odps.udf import annotate\n"
"from odps.distcache import get_cache_file\n"
"\n"
"@annotate('bigint->bigint')\n"
"class Example(object):\n"
"    def __init__(self):\n"
"        self.n = int(get_cache_file('test_alias_res1').read())\n"
"\n"
"    def evaluate(self, arg):\n"
"        return arg + self.n\n"
"'''\n"
"res1 = o.create_resource('test_alias_res1', 'file', file_obj='1')\n"
"o.create_resource('test_alias.py', 'py', file_obj=myfunc)\n"
"o.create_function('test_alias_func',\n"
"                  class_type='test_alias.Example',\n"
"                  resources=['test_alias.py', 'test_alias_res1'])\n"
"\n"
"table = o.create_table(\n"
"    'test_table',\n"
"    schema=Schema.from_lists(['size'], ['bigint']),\n"
"    if_not_exists=True\n"
")\n"
"\n"
"data = [[1, ], ]\n"
"# 写入一行数据，只包含一个值1\n"
"o.write_table(table, 0, [table.new_record(it) for it in data])\n"
"\n"
"with o.execute_sql(\n"
"    'select test_alias_func(size) from test_table').open_reader() as "
"reader:\n"
"    print(reader[0][0])"
msgstr ""
"from odps.models import Schema\n"
"\n"
"myfunc = '''\\\n"
"from odps.udf import annotate\n"
"from odps.distcache import get_cache_file\n"
"\n"
"@annotate('bigint->bigint')\n"
"class Example(object):\n"
"    def __init__(self):\n"
"        self.n = int(get_cache_file('test_alias_res1').read())\n"
"\n"
"    def evaluate(self, arg):\n"
"        return arg + self.n\n"
"'''\n"
"res1 = o.create_resource('test_alias_res1', 'file', file_obj='1')\n"
"o.create_resource('test_alias.py', 'py', file_obj=myfunc)\n"
"o.create_function('test_alias_func',\n"
"                  class_type='test_alias.Example',\n"
"                  resources=['test_alias.py', 'test_alias_res1'])\n"
"\n"
"table = o.create_table(\n"
"    'test_table',\n"
"    schema=Schema.from_lists(['size'], ['bigint']),\n"
"    if_not_exists=True\n"
")\n"
"\n"
"data = [[1, ], ]\n"
"# write one row with only one value '1'\n"
"o.write_table(table, 0, [table.new_record(it) for it in data])\n"
"\n"
"with o.execute_sql(\n"
"    'select test_alias_func(size) from test_table').open_reader() as "
"reader:\n"
"    print(reader[0][0])"

#: ../../source/base-sql.rst:158
msgid "2"
msgstr ""

#: ../../source/base-sql.rst:162
msgid ""
"res2 = o.create_resource('test_alias_res2', 'file', file_obj='2')\n"
"# 把内容为1的资源alias成内容为2的资源，我们不需要修改UDF或资源\n"
"with o.execute_sql(\n"
"    'select test_alias_func(size) from test_table',\n"
"    aliases={'test_alias_res1': 'test_alias_res2'}).open_reader() as "
"reader:\n"
"    print(reader[0][0])"
msgstr ""
"res2 = o.create_resource('test_alias_res2', 'file', file_obj='2')\n"
"# When we need to replace resource with value '1' with resource with "
"value '2',\n"
"# the only thing we need to do is to use alias argument. Modifying UDFs "
"or resources is not needed.\n"
"with o.execute_sql(\n"
"    'select test_alias_func(size) from test_table',\n"
"    aliases={'test_alias_res1': 'test_alias_res2'}).open_reader() as "
"reader:\n"
"    print(reader[0][0])"

#: ../../source/base-sql.rst:171
msgid "3"
msgstr ""

#: ../../source/base-sql.rst:177
msgid "在交互式环境执行 SQL"
msgstr "Execute SQL statements in an interactive environment"

#: ../../source/base-sql.rst:179
msgid ""
"在 ipython 和 jupyter 里支持 :ref:`使用 SQL 插件的方式运行 SQL <sqlinter>`，且支持 "
":ref:`参数化查询 <sqlparam>`， 详情参阅 :ref:`文档 <sqlinter>`。"
msgstr ""
"In ipython and jupyter, you can :ref:`use SQL plugins to execute SQL "
"statements<sqlinter>`. Besides, :ref:`parameterized query<sqlparam>` is "
"also supported. For details, see :ref:`Documentation<sqlinter>`."

#: ../../source/base-sql.rst:185
msgid "设置 biz_id"
msgstr "Set biz_id"

#: ../../source/base-sql.rst:187
msgid "在少数情形下，可能在提交 SQL 时，需要同时提交 biz_id，否则执行会报错。此时，你可以设置全局 options 里的 biz_id。"
msgstr ""
"In a few cases, it may be necessary to submit biz_id when submitting SQL "
"statements. Otherwise an error occurs during execution. You can set the "
"biz_id in options globally."

#: ../../source/base-sql.rst:189
msgid ""
"from odps import options\n"
"\n"
"options.biz_id = 'my_biz_id'\n"
"o.execute_sql('select * from pyodps_iris')"
msgstr ""

