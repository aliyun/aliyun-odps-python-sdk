# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-2018, The Alibaba Group Holding Ltd.
# This file is distributed under the same license as the PyODPS package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PyODPS 0.7.16\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-06-29 16:26+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/base-tables.rst:4
msgid "表"
msgstr "Tables"

#: ../../source/base-tables.rst:6
msgid ""
"`表 <https://docs.aliyun.com/#/pub/odps/basic/definition&table>`_ "
"是ODPS的数据存储单元。"
msgstr ""
"`Tables <https://www.alibabacloud.com/help/en/doc-detail/27819.htm>`_ are"
" the data storage unit in MaxCompute."

#: ../../source/base-tables.rst:9 ../../source/base-tables.rst:364
msgid "基本操作"
msgstr "Basic operations"

#: ../../source/base-tables.rst:11
msgid "我们可以用 ODPS 入口对象的 ``list_tables`` 来列出项目空间下的所有表。"
msgstr ""
"Use the ``list_tables`` method as the ODPS object to list all tables in a"
" project."

#: ../../source/base-tables.rst:13
msgid ""
"for table in o.list_tables():\n"
"    # 处理每个表"
msgstr ""
"for table in o.list_tables():\n"
"    # handle every table"

#: ../../source/base-tables.rst:18
msgid "通过调用 ``exist_table`` 来判断表是否存在。"
msgstr "Use ``exist_table`` to check whether the specified table exists."

#: ../../source/base-tables.rst:20
msgid "通过调用 ``get_table`` 来获取表。"
msgstr "Use ``get_table`` to obtain the specified table."

#: ../../source/base-tables.rst:22
msgid ""
">>> t = o.get_table('dual')\n"
">>> t.schema\n"
"odps.Schema {\n"
"  c_int_a                 bigint\n"
"  c_int_b                 bigint\n"
"  c_double_a              double\n"
"  c_double_b              double\n"
"  c_string_a              string\n"
"  c_string_b              string\n"
"  c_bool_a                boolean\n"
"  c_bool_b                boolean\n"
"  c_datetime_a            datetime\n"
"  c_datetime_b            datetime\n"
"}\n"
">>> t.lifecycle\n"
"-1\n"
">>> print(t.creation_time)\n"
"2014-05-15 14:58:43\n"
">>> t.is_virtual_view\n"
"False\n"
">>> t.size\n"
"1408\n"
">>> t.comment\n"
"'Dual Table Comment'\n"
">>> t.schema.columns\n"
"[<column c_int_a, type bigint>,\n"
" <column c_int_b, type bigint>,\n"
" <column c_double_a, type double>,\n"
" <column c_double_b, type double>,\n"
" <column c_string_a, type string>,\n"
" <column c_string_b, type string>,\n"
" <column c_bool_a, type boolean>,\n"
" <column c_bool_b, type boolean>,\n"
" <column c_datetime_a, type datetime>,\n"
" <column c_datetime_b, type datetime>]\n"
">>> t.schema['c_int_a']\n"
"<column c_int_a, type bigint>\n"
">>> t.schema['c_int_a'].comment\n"
"'Comment of column c_int_a'"
msgstr ""

#: ../../source/base-tables.rst:65
msgid "通过提供 ``project`` 参数，来跨project获取表。"
msgstr ""
"You can also provide the ``project`` parameter to obtain the specified "
"table from another project."

#: ../../source/base-tables.rst:67
msgid ">>> t = o.get_table('dual', project='other_project')"
msgstr ""

#: ../../source/base-tables.rst:75
msgid "创建表的Schema"
msgstr "Create the table schema"

#: ../../source/base-tables.rst:77
msgid "有两种方法来初始化。第一种方式通过表的列、以及可选的分区来初始化。"
msgstr ""
"You can initialize a table in two ways. First, you can use columns or "
"combination of columns and partitions columns to initialize the table."

#: ../../source/base-tables.rst:79
msgid ""
">>> from odps.models import Schema, Column, Partition\n"
">>> columns = [Column(name='num', type='bigint', comment='the column'),\n"
">>>            Column(name='num2', type='double', comment='the column2')]"
"\n"
">>> partitions = [Partition(name='pt', type='string', comment='the "
"partition')]\n"
">>> schema = Schema(columns=columns, partitions=partitions)\n"
">>> schema.columns\n"
"[<column num, type bigint>,\n"
" <column num2, type double>,\n"
" <partition pt, type string>]\n"
">>> schema.partitions\n"
"[<partition pt, type string>]\n"
">>> schema.names  # 获取非分区字段的字段名\n"
"['num', 'num2']\n"
">>> schema.types  # 获取非分区字段的字段类型\n"
"[bigint, double]"
msgstr ""
">>> from odps.models import Schema, Column, Partition\n"
">>> columns = [Column(name='num', type='bigint', comment='the column'),\n"
">>>            Column(name='num2', type='double', comment='the column2')]"
"\n"
">>> partitions = [Partition(name='pt', type='string', comment='the "
"partition')]\n"
">>> schema = Schema(columns=columns, partitions=partitions)\n"
">>> schema.columns\n"
"[<column num, type bigint>,\n"
" <column num2, type double>,\n"
" <partition pt, type string>]\n"
">>> schema.partitions\n"
"[<partition pt, type string>]\n"
">>> schema.names  # get column name of none-partition columns\n"
"['num', 'num2']\n"
">>> schema.types  # get column type of none-partition columns\n"
"[bigint, double]"

#: ../../source/base-tables.rst:98
msgid "第二种方法是使用 ``Schema.from_lists``，这种方法更容易调用，但显然无法直接设置列和分区的注释了。"
msgstr ""
"Second, you can use ``Schema.from_lists`` to initialize the table. This "
"method is easier, but you cannot directly set the comments of the columns"
" and the partitions."

#: ../../source/base-tables.rst:100
msgid ""
">>> schema = Schema.from_lists(['num', 'num2'], ['bigint', 'double'], "
"['pt'], ['string'])\n"
">>> schema.columns\n"
"[<column num, type bigint>,\n"
" <column num2, type double>,\n"
" <partition pt, type string>]"
msgstr ""

#: ../../source/base-tables.rst:109
msgid "创建表"
msgstr "Create tables"

#: ../../source/base-tables.rst:111
msgid "可以使用表 schema 来创建表，方法如下："
msgstr "You can use the table schema to create a table in the following way:"

#: ../../source/base-tables.rst:113
msgid ""
">>> table = o.create_table('my_new_table', schema)\n"
">>> table = o.create_table('my_new_table', schema, if_not_exists=True)  #"
" 只有不存在表时才创建\n"
">>> table = o.create_table('my_new_table', schema, lifecycle=7)  # 设置生命周期"
msgstr ""
">>> table = o.create_table('my_new_table', schema)\n"
">>> table = o.create_table('my_new_table', schema, if_not_exists=True)  #"
" create table only when the table does not exist\n"
">>> table = o.create_table('my_new_table', schema, lifecycle=7)  # "
"configure lifecycle of the table (in days)"

#: ../../source/base-tables.rst:120
msgid "更简单的方式是采用“字段名 字段类型”字符串来创建表，方法如下："
msgstr ""
"An easier way is to use a string in the structure of “field name field "
"type” to create the table, as shown in the following code:"

#: ../../source/base-tables.rst:122
msgid ""
">>> table = o.create_table('my_new_table', 'num bigint, num2 double', "
"if_not_exists=True)\n"
">>> # 创建分区表可传入 (表字段列表, 分区字段列表)\n"
">>> table = o.create_table('my_new_table', ('num bigint, num2 double', "
"'pt string'), if_not_exists=True)"
msgstr ""
">>> table = o.create_table('my_new_table', 'num bigint, num2 double', "
"if_not_exists=True)\n"
">>> # a tuple like (column list, partition list) can be passed to create "
"a partitioned table\n"
">>> table = o.create_table('my_new_table', ('num bigint, num2 double', "
"'pt string'), if_not_exists=True)"

#: ../../source/base-tables.rst:129
msgid ""
"在未经设置的情况下，创建表时，只允许使用 bigint、double、decimal、string、datetime、boolean、map 和 "
"array 类型。 如果你使用的是位于公共云上的服务，或者支持 tinyint、struct 等新类型，可以设置 "
"``options.sql.use_odps2_extension = True`` 打开这些类型的支持，示例如下："
msgstr ""
"By default, you can only use the bigint, double, decimal, string, "
"datetime, boolean, map and array types to create a table. If you use "
"public cloud services, you can set ``options.sql.use_odps2_extension = "
"True`` to enable more types such as tinyint and struct, as shown in the "
"following code:"

#: ../../source/base-tables.rst:133
msgid ""
">>> from odps import options\n"
">>> options.sql.use_odps2_extension = True\n"
">>> table = o.create_table('my_new_table', 'cat smallint, content "
"struct<title:varchar(100), body string>')"
msgstr ""

#: ../../source/base-tables.rst:141
msgid "同步表更新"
msgstr "Synchronize table updates"

#: ../../source/base-tables.rst:143
msgid "有时候，一个表可能被别的程序做了更新，比如schema有了变化。此时可以调用 ``reload`` 方法来更新。"
msgstr ""
"If a table has been updated by another program and has changes in the "
"schema, you can use ``reload`` to synchronize the update."

#: ../../source/base-tables.rst:145
msgid ">>> table.reload()"
msgstr ""

#: ../../source/base-tables.rst:151
msgid "行记录Record"
msgstr "Record"

#: ../../source/base-tables.rst:153
msgid "Record表示表的一行记录，我们在 Table 对象上调用 new_record 就可以创建一个新的 Record。"
msgstr ""
"A record is a row record in a table. You can use new_record of a table "
"object to create a new record."

#: ../../source/base-tables.rst:155
msgid ""
">>> t = o.get_table('mytable')\n"
">>> r = t.new_record(['val0', 'val1'])  # 值的个数必须等于表schema的字段数\n"
">>> r2 = t.new_record()  #  也可以不传入值\n"
">>> r2[0] = 'val0' # 可以通过偏移设置值\n"
">>> r2['field1'] = 'val1'  # 也可以通过字段名设置值\n"
">>> r2.field1 = 'val1'  # 通过属性设置值\n"
">>>\n"
">>> print(record[0])  # 取第0个位置的值\n"
">>> print(record['c_double_a'])  # 通过字段取值\n"
">>> print(record.c_double_a)  # 通过属性取值\n"
">>> print(record[0: 3])  # 切片操作\n"
">>> print(record[0, 2, 3])  # 取多个位置的值\n"
">>> print(record['c_int_a', 'c_double_a'])  # 通过多个字段取值"
msgstr ""
">>> t = o.get_table('mytable')\n"
">>> r = t.new_record(['val0', 'val1'])  # the number of values must be "
"the same with the number of columns in the schema\n"
">>> r2 = t.new_record()  # initializing without values is also acceptable"
"\n"
">>> r2[0] = 'val0' # values can be set via column indices\n"
">>> r2['field1'] = 'val1'  # values can also be set via column names\n"
">>> r2.field1 = 'val1'  # values can also be set via attributes\n"
">>>\n"
">>> print(record[0])  # get the value of Column 0\n"
">>> print(record['c_double_a'])  # get value via column name\n"
">>> print(record.c_double_a)  # get value via attributes\n"
">>> print(record[0: 3])  # slice over the column\n"
">>> print(record[0, 2, 3])  # get multiple values via indices\n"
">>> print(record['c_int_a', 'c_double_a'])  # get multiple values via "
"column names"

#: ../../source/base-tables.rst:175
msgid "获取表数据"
msgstr "Obtain table data"

#: ../../source/base-tables.rst:177
msgid "有若干种方法能够获取表数据。首先，如果只是查看每个表的开始的小于1万条数据，则可以使用 ``head`` 方法。"
msgstr ""
"You can obtain table data in different ways. First, you can use ``head`` "
"to retrieve the first 10,000 or fewer data items in each table."

#: ../../source/base-tables.rst:179
msgid ""
">>> t = o.get_table('dual')\n"
">>> for record in t.head(3):\n"
">>>     # 处理每个Record对象"
msgstr ""
">>> t = o.get_table('dual')\n"
">>> for record in t.head(3):\n"
">>>     # process every Record object"

#: ../../source/base-tables.rst:188
msgid "其次，在table上可以执行 ``open_reader`` 操作来打一个reader来读取数据。"
msgstr ""
"Then, use ``open_reader`` as the table object to open a reader and read "
"the data."

#: ../../source/base-tables.rst:190 ../../source/base-tables.rst:249
msgid "使用 with 表达式的写法："
msgstr "Open the reader using a WITH clause, as shown in the following code:"

#: ../../source/base-tables.rst:192
msgid ""
">>> with t.open_reader(partition='pt=test') as reader:\n"
">>>     count = reader.count\n"
">>>     for record in reader[5:10]  # "
"可以执行多次，直到将count数量的record读完，这里可以改造成并行操作\n"
">>>         # 处理一条记录"
msgstr ""
">>> with t.open_reader(partition='pt=test') as reader:\n"
">>>     count = reader.count\n"
">>>     for record in reader[5:10]  # This line can be executed many "
"times until all records are visited. Parallelism can also be introduced."
"\n"
">>>         # process one record"

#: ../../source/base-tables.rst:199
msgid "不使用 with 表达式的写法："
msgstr ""
"Open the reader without using a WITH clause, as shown in the following "
"code:"

#: ../../source/base-tables.rst:201
msgid ""
">>> reader = t.open_reader(partition='pt=test')\n"
">>> count = reader.count\n"
">>> for record in reader[5:10]  # 可以执行多次，直到将count数量的record读完，这里可以改造成并行操作\n"
">>>     # 处理一条记录"
msgstr ""
">>> with t.open_reader(partition='pt=test') as reader:\n"
">>>     count = reader.count\n"
">>>     for record in reader[5:10]  # This line can be executed many "
"times until all records are visited. Parallelism can also be introduced."
"\n"
">>>         # process one record"

#: ../../source/base-tables.rst:208
msgid "直接读取成 Pandas DataFrame:"
msgstr "Read directly into Pandas DataFrames:"

#: ../../source/base-tables.rst:210
msgid ""
">>> with t.open_reader(partition='pt=test') as reader:\n"
">>>     pd_df = reader.to_pandas()"
msgstr ""

#: ../../source/base-tables.rst:218
msgid "利用多进程加速读取:"
msgstr "Accelerate data read using multiple processes:"

#: ../../source/base-tables.rst:222
msgid "目前多进程加速在 Windows 下无法使用。"
msgstr "Currently acceleration using multiple processes is not available under Windows."

#: ../../source/base-tables.rst:225
msgid ""
">>> import multiprocessing\n"
">>> n_process = multiprocessing.cpu_count()\n"
">>> with t.open_reader(partition='pt=test') as reader:\n"
">>>     pd_df = reader.to_pandas(n_process=n_process)"
msgstr ""

#: ../../source/base-tables.rst:233
msgid "更简单的调用方法是使用 ODPS 对象的 ``read_table`` 方法，例如"
msgstr ""
"An easier way is to use ``read_table`` as the ODPS object, as shown in "
"the following code:"

#: ../../source/base-tables.rst:235
msgid ""
">>> for record in o.read_table('test_table', partition='pt=test'):\n"
">>>     # 处理一条记录"
msgstr ""
">>> for record in o.read_table('test_table', partition='pt=test'):\n"
">>>     # process one record"

#: ../../source/base-tables.rst:245
msgid "向表写数据"
msgstr "Write data to tables"

#: ../../source/base-tables.rst:247
msgid "类似于 ``open_reader``，table对象同样能执行 ``open_writer`` 来打开writer，并写数据。"
msgstr ""
"Similar to ``open_reader``, you can use ``open_writer`` as the table "
"object to open a writer and write data to the table."

#: ../../source/base-tables.rst:251
msgid ""
">>> with t.open_writer(partition='pt=test') as writer:\n"
">>>     records = [[111, 'aaa', True],                 # 这里可以是list\n"
">>>                [222, 'bbb', False],\n"
">>>                [333, 'ccc', True],\n"
">>>                [444, '中文', False]]\n"
">>>     writer.write(records)  # 这里records可以是可迭代对象\n"
">>>\n"
">>>     records = [t.new_record([111, 'aaa', True]),   # 也可以是Record对象\n"
">>>                t.new_record([222, 'bbb', False]),\n"
">>>                t.new_record([333, 'ccc', True]),\n"
">>>                t.new_record([444, '中文', False])]\n"
">>>     writer.write(records)\n"
">>>"
msgstr ""
">>> with t.open_writer(partition='pt=test') as writer:\n"
">>>     records = [[111, 'aaa', True],                 # a list can be "
"used here\n"
">>>                [222, 'bbb', False],\n"
">>>                [333, 'ccc', True],\n"
">>>                [444, '中文', False]]\n"
">>>     writer.write(records)  # records can also be iterable objects\n"
">>>\n"
">>>     records = [t.new_record([111, 'aaa', True]),   # a list with "
"records can also be used\n"
">>>                t.new_record([222, 'bbb', False]),\n"
">>>                t.new_record([333, 'ccc', True]),\n"
">>>                t.new_record([444, '中文', False])]\n"
">>>     writer.write(records)\n"
">>>"

#: ../../source/base-tables.rst:268
msgid "如果分区不存在，可以使用 ``create_partition`` 参数指定创建分区，如"
msgstr ""
"If the specified partition does not exist, use the ``create_partition`` "
"parameter to create a partition, as shown in the following code:"

#: ../../source/base-tables.rst:270
msgid ""
">>> with t.open_writer(partition='pt=test', create_partition=True) as "
"writer:\n"
">>>     records = [[111, 'aaa', True],                 # 这里可以是list\n"
">>>                [222, 'bbb', False],\n"
">>>                [333, 'ccc', True],\n"
">>>                [444, '中文', False]]\n"
">>>     writer.write(records)  # 这里records可以是可迭代对象"
msgstr ""
">>> with t.open_writer(partition='pt=test', create_partition=True) as "
"writer:\n"
">>>     records = [[111, 'aaa', True],                 # a list can be "
"used here\n"
">>>                [222, 'bbb', False],\n"
">>>                [333, 'ccc', True],\n"
">>>                [444, '中文', False]]\n"
">>>     writer.write(records)  # records can also be iterable objects"

#: ../../source/base-tables.rst:279
msgid "更简单的写数据方法是使用 ODPS 对象的 write_table 方法，例如"
msgstr ""
"An easier way is to use write_table as the ODPS object to write data, as "
"shown in the following code:"

#: ../../source/base-tables.rst:281
msgid ""
">>> records = [[111, 'aaa', True],                 # 这里可以是list\n"
">>>            [222, 'bbb', False],\n"
">>>            [333, 'ccc', True],\n"
">>>            [444, '中文', False]]\n"
">>> o.write_table('test_table', records, partition='pt=test', "
"create_partition=True)"
msgstr ""
">>> records = [[111, 'aaa', True],                 # a list can be used "
"here\n"
">>>            [222, 'bbb', False],\n"
">>>            [333, 'ccc', True],\n"
">>>            [444, '中文', False]]\n"
">>> o.write_table('test_table', records, partition='pt=test', "
"create_partition=True)"

#: ../../source/base-tables.rst:291
msgid ""
"**注意**\\ ：每次调用 write_table，MaxCompute 都会在服务端生成一个文件。这一操作需要较大的时间开销， "
"同时过多的文件会降低后续的查询效率。因此，我们建议在使用 write_table 方法时，一次性写入多组数据， 或者传入一个 generator "
"对象。"
msgstr ""
"**Note**\\ ：Every time when ``write_table`` is invoked，MaxCompute "
"generates a new file on the server side, which is an expensive operation "
"that reduces the throughput drastically. What's more, too many files may "
"increase query time on that table. Hence we propose writing multiple "
"records or passing a Python generator object when calling "
"``write_table``."

#: ../../source/base-tables.rst:295
msgid ""
"write_table 写表时会追加到原有数据。PyODPS 不提供覆盖数据的选项，如果需要覆盖数据，需要手动清除 "
"原有数据。对于非分区表，需要调用 table.truncate()，对于分区表，需要删除分区后再建立。"
msgstr ""
"When calling ```write_table```, new data will be appended to existing "
"data. PyODPS does not provide options to overwrite existing data. When "
"overwriting is needed, you need to explicitly remove existing data in "
"tables by calling table.truncate() en unpartitioned tables or removing "
"partitions in partitioned tables."

#: ../../source/base-tables.rst:298
msgid "使用多进程并行写数据："
msgstr "Use multiple processes to write records:"

#: ../../source/base-tables.rst:300
msgid ""
"每个进程写数据时共享同一个 session_id，但是有不同的 block_id，每个 block 对应服务端的一个文件， 最后主进程执行 "
"commit，完成数据上传。"
msgstr ""
"All processes share one single session_id but own different block_id, each block_id represents "
"a server-side file respectively. After all writing done the main process commits and data are uploaded."

#: ../../source/base-tables.rst:303
msgid ""
"import random\n"
"from multiprocessing import Pool\n"
"from odps.tunnel import TableTunnel\n"
"\n"
"def write_records(session_id, block_id):\n"
"    # 使用指定的 id 创建 session\n"
"    local_session = tunnel.create_upload_session(table.name, "
"upload_id=session_id)\n"
"    # 创建 writer 时指定 block_id\n"
"    with local_session.open_record_writer(block_id) as writer:\n"
"        for i in range(5):\n"
"            # 生成数据并写入对应 block\n"
"            record = table.new_record([random.randint(1, 100), "
"random.random()])\n"
"            writer.write(record)\n"
"\n"
"if __name__ == '__main__':\n"
"    N_WORKERS = 3\n"
"\n"
"    table = o.create_table('my_new_table', 'num bigint, num2 double', "
"if_not_exists=True)\n"
"    tunnel = TableTunnel(o)\n"
"    upload_session = tunnel.create_upload_session(table.name)\n"
"\n"
"    # 每个进程使用同一个 session_id\n"
"    session_id = upload_session.id\n"
"\n"
"    pool = Pool(processes=N_WORKERS)\n"
"    futures = []\n"
"    block_ids = []\n"
"    for i in range(N_WORKERS):\n"
"        futures.append(pool.apply_async(write_records, (session_id, i)))\n"
"        block_ids.append(i)\n"
"    [f.get() for f in futures]\n"
"\n"
"    # 最后执行 commit，并指定所有 block\n"
"    upload_session.commit(block_ids)"
msgstr ""
"import random\n"
"from multiprocessing import Pool\n"
"from odps.tunnel import TableTunnel\n"
"\n"
"def write_records(session_id, block_id):\n"
"    # create sessions with given id from main process\n"
"    local_session = tunnel.create_upload_session(table.name, "
"upload_id=session_id)\n"
"    # specify block_id when creating writers\n"
"    with local_session.open_record_writer(block_id) as writer:\n"
"        for i in range(5):\n"
"            # generate data and write to corresponding blocks\n"
"            record = table.new_record([random.randint(1, 100), "
"random.random()])\n"
"            writer.write(record)\n"
"\n"
"if __name__ == '__main__':\n"
"    N_WORKERS = 3\n"
"\n"
"    table = o.create_table('my_new_table', 'num bigint, num2 double', "
"if_not_exists=True)\n"
"    tunnel = TableTunnel(o)\n"
"    upload_session = tunnel.create_upload_session(table.name)\n"
"\n"
"    # all processes share one single session_id\n"
"    session_id = upload_session.id\n"
"\n"
"    pool = Pool(processes=N_WORKERS)\n"
"    futures = []\n"
"    block_ids = []\n"
"    for i in range(N_WORKERS):\n"
"        futures.append(pool.apply_async(write_records, (session_id, i)))\n"
"        block_ids.append(i)\n"
"    [f.get() for f in futures]\n"
"\n"
"    # finally we call commit with all block_ids\n"
"    upload_session.commit(block_ids)"

#: ../../source/base-tables.rst:341
msgid "删除表"
msgstr "Delete tables"

#: ../../source/base-tables.rst:343
msgid ""
">>> o.delete_table('my_table_name', if_exists=True)  #  只有表存在时删除\n"
">>> t.drop()  # Table对象存在的时候可以直接执行drop函数"
msgstr ""
">>> o.delete_table('my_table_name', if_exists=True)  #  delete only when "
"the table exists\n"
">>> t.drop()  # call drop method of the Table object to delete directly"

#: ../../source/base-tables.rst:350
msgid "创建DataFrame"
msgstr "Create a DataFrame"

#: ../../source/base-tables.rst:352
msgid ""
"PyODPS提供了 :ref:`DataFrame框架 <df>` ，支持更方便地方式来查询和操作ODPS数据。 使用 ``to_df`` "
"方法，即可转化为 DataFrame 对象。"
msgstr ""
"PyODPS provides a :ref:`DataFrame framework <df>` to easily search and "
"operate MaxCompute data. You can use ``to_df`` to convert a table to a "
"DataFrame object."

#: ../../source/base-tables.rst:355
msgid ""
">>> table = o.get_table('my_table_name')\n"
">>> df = table.to_df()"
msgstr ""

#: ../../source/base-tables.rst:361
msgid "表分区"
msgstr "Table partitions"

#: ../../source/base-tables.rst:366
msgid "判断是否为分区表："
msgstr "Check if a table is partitioned:"

#: ../../source/base-tables.rst:368
#, python-format
msgid ""
">>> if table.schema.partitions:\n"
">>>     print('Table %s is partitioned.' % table.name)"
msgstr ""

#: ../../source/base-tables.rst:373
msgid "遍历表全部分区："
msgstr "Iterate through all the partitions in a table:"

#: ../../source/base-tables.rst:375
msgid ""
">>> for partition in table.partitions:\n"
">>>     print(partition.name)\n"
">>> for partition in table.iterate_partitions(spec='pt=test'):\n"
">>>     # 遍历二级分区"
msgstr ""
">>> for partition in table.partitions:\n"
">>>     print(partition.name)\n"
">>> for partition in table.iterate_partitions(spec='pt=test'):\n"
">>>     # iterate over secondary partitions"

#: ../../source/base-tables.rst:382
msgid "判断分区是否存在（该方法需要填写所有分区字段值）："
msgstr ""
"Check whether the specified partition exists, all field values should be "
"provided:"

#: ../../source/base-tables.rst:384
msgid ">>> table.exist_partition('pt=test,sub=2015')"
msgstr ""

#: ../../source/base-tables.rst:388
msgid "判断给定前缀的分区是否存在："
msgstr "Check whether partitions satisfying provided prefix exist:"

#: ../../source/base-tables.rst:390
msgid ""
">>> # 表 table 的分区字段依次为 pt, sub\n"
">>> table.exist_partitions('pt=test')"
msgstr ""
">>> # the order of partitions fields of table is pt, sub\n"
">>> table.exist_partitions('pt=test')"

#: ../../source/base-tables.rst:395
msgid "获取分区："
msgstr "Obtain the specified partition:"

#: ../../source/base-tables.rst:397
msgid ""
">>> partition = table.get_partition('pt=test')\n"
">>> print(partition.creation_time)\n"
"2015-11-18 22:22:27\n"
">>> partition.size\n"
"0"
msgstr ""

#: ../../source/base-tables.rst:406
msgid "创建分区"
msgstr "Create partitions"

#: ../../source/base-tables.rst:408
msgid ">>> t.create_partition('pt=test', if_not_exists=True)  # 不存在的时候才创建"
msgstr ""
">>> t.create_partition('pt=test', if_not_exists=True)  # create only when"
" the partition does not exist"

#: ../../source/base-tables.rst:413
msgid "删除分区"
msgstr "Delete partitions"

#: ../../source/base-tables.rst:415
msgid ""
">>> t.delete_partition('pt=test', if_exists=True)  # 存在的时候才删除\n"
">>> partition.drop()  # Partition对象存在的时候直接drop"
msgstr ""
">>> t.delete_partition('pt=test', if_exists=True)  # delete only when the"
" partition exists\n"
">>> partition.drop()  # delete directly via the drop method of the "
"partition object"

#: ../../source/base-tables.rst:423
msgid "数据上传下载通道"
msgstr "Data upload and download channels"

#: ../../source/base-tables.rst:428
msgid ""
"不推荐直接使用tunnel接口（难用且复杂），推荐直接使用表的 :ref:`写 <table_write>` 和 :ref:`读 "
"<table_read>` 接口。"
msgstr ""
"If you just need to upload a small amount of data, we do not recommend "
"using table tunnel directly as there are more convenient :ref:`read "
"<table_read>` and :ref:`write <table_write>` methods which wraps table "
"tunnel invocations. However, when your data amount is large and "
"throughput is critical, you may try using table tunnel methods directly."

#: ../../source/base-tables.rst:432
msgid "ODPS Tunnel是ODPS的数据通道，用户可以通过Tunnel向ODPS中上传或者下载数据。"
msgstr ""
"MaxCompute Tunnel is the data channel of MaxCompute. You can use this to "
"upload data to or download data from MaxCompute."

#: ../../source/base-tables.rst:434
msgid "**注意**，如果安装了 **Cython**，在安装pyodps时会编译C代码，加速Tunnel的上传和下载。"
msgstr ""
"**Note**: In a **Cython** environment, PyODPS compiles C programs during "
"installation to increase the Tunnel upload and download speed when "
"required."

#: ../../source/base-tables.rst:437
msgid "上传"
msgstr "Upload"

#: ../../source/base-tables.rst:439
msgid ""
"from odps.tunnel import TableTunnel\n"
"\n"
"table = o.get_table('my_table')\n"
"\n"
"tunnel = TableTunnel(odps)\n"
"upload_session = tunnel.create_upload_session(table.name, "
"partition_spec='pt=test')\n"
"\n"
"with upload_session.open_record_writer(0) as writer:\n"
"    record = table.new_record()\n"
"    record[0] = 'test1'\n"
"    record[1] = 'id1'\n"
"    writer.write(record)\n"
"\n"
"    record = table.new_record(['test2', 'id2'])\n"
"    writer.write(record)\n"
"\n"
"upload_session.commit([0])"
msgstr ""

#: ../../source/base-tables.rst:459
msgid "也可以使用流式上传的接口："
msgstr "You can also use stream-like upload interface:"

#: ../../source/base-tables.rst:461
msgid ""
"from odps.tunnel import TableTunnel\n"
"\n"
"table = o.get_table('my_table')\n"
"\n"
"tunnel = TableTunnel(odps)\n"
"upload_session = tunnel.create_stream_upload_session(table.name, "
"partition_spec='pt=test')\n"
"\n"
"with upload_session.open_record_writer() as writer:\n"
"    record = table.new_record()\n"
"    record[0] = 'test1'\n"
"    record[1] = 'id1'\n"
"    writer.write(record)\n"
"\n"
"    record = table.new_record(['test2', 'id2'])\n"
"    writer.write(record)"
msgstr ""

#: ../../source/base-tables.rst:481
msgid "下载"
msgstr "Download"

#: ../../source/base-tables.rst:484
msgid ""
"from odps.tunnel import TableTunnel\n"
"\n"
"tunnel = TableTunnel(odps)\n"
"download_session = tunnel.create_download_session('my_table', "
"partition_spec='pt=test')\n"
"\n"
"with download_session.open_record_reader(0, download_session.count) as "
"reader:\n"
"    for record in reader:\n"
"        # 处理每条记录"
msgstr ""
"from odps.tunnel import TableTunnel\n"
"\n"
"tunnel = TableTunnel(odps)\n"
"download_session = tunnel.create_download_session('my_table', "
"partition_spec='pt=test')\n"
"\n"
"with download_session.open_record_reader(0, download_session.count) as "
"reader:\n"
"    for record in reader:\n"
"        # process every record"

